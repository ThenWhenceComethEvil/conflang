= Notes
:toc:                      left
:toclevels:                3
:source-highlighter:       pygments
:pygments-style:           algol_nu
:pygments-linenums-mode:   table

Collections of my thinkies, musings, and stuff to refer back to while working on this.


== Bash tomfoolery
Naturally, any project of mine must contain a fair amount of bash tomfoolery.

=== Set, but empty
There are built-in tests for variables that are empty _or_ unset (`test -z`).
However none for declared _and_ empty.
Did some testing to verify how all the parameter expansion for unset/empty vars works:

[source,bash]
----
# Set, empty.
declare -- se=

# Set, non-empty.
declare -- ne='set'

# Non-set
#declare -- ns

#    TEST                          #      SET      VALUE     RESULT   
#---------------------------------------------------------------------
[[ ${ne}     ]] && echo  "ne"      #      YES       YES      TRUE
[[ ${se}     ]] && echo  "se"      #      YES        NO      FALSE
[[ ${ns}     ]] && echo  "ns"      #       NO       ---      FALSE

[[ ${ne-_}   ]] && echo  "ne-_"    #      YES       YES      TRUE
[[ ${se-_}   ]] && echo  "se-_"    #      YES        NO      FALSE
[[ ${ns-_}   ]] && echo  "ns-_"    #       NO       ---      TRUE

[[ ${ne:-_}  ]] && echo  "ne:-_"   #      YES       YES      TRUE
[[ ${se:-_}  ]] && echo  "se:-_"   #      YES        NO      TRUE
[[ ${ns:-_}  ]] && echo  "ns:-_"   #       NO       ---      TRUE

[[ ${ne+_}   ]] && echo  "ne+_"    #      YES       YES      TRUE
[[ ${se+_}   ]] && echo  "se+_"    #      YES        NO      TRUE
[[ ${ns+_}   ]] && echo  "ns+_"    #       NO       ---      FALSE

[[ ${ne:+_}  ]] && echo  "ne:+_"   #      YES       YES      TRUE
[[ ${se:+_}  ]] && echo  "se:+_"   #      YES        NO      FALSE
[[ ${ns:+_}  ]] && echo  "ns:+_"   #       NO       ---      FALSE

# TO USE...
# Find a section in which the desired value has a unique result. E.g., where
# the result of ${ns...} is not the same as the result of `ne` or `se`.

# Results...
#  UNSET              [[ ! ${var+_} ]]
#  SET AND EMPTY      [[ ! ${var-_} ]]
#  SET AND NONEMPTY   [[   ${var}   ]]
----


== Properties vs. asserts
I think I've been low-key struggling to justify the "`assert`" piece of the syntax.
I know I wanted something to say "`this value should have some required information`".
Perhaps that was mistakenly ``assert``s, rather than '`properties`'.
Each type has a set of valid properties (obviously user-extensible) that are enforced at runtime.

[source]
----
dirs  array:path  [
   ~/Desktop
   ~/Documents
   ~/Pictures/
] {
   create       : true;
   can('read')  : true;
   can('write') : false;
   elements     : 3;
}
----

'`Properties`' as a concept I think is much more apt for describing the role they play.

It is the next day, and I am thinking about this further.
Isn't `create : true` the same thing as just saying `create`?
We can probably assume a truthy value.

I was thinking maybe there wasn't too much of a practical difference to an `assert` rather than a '`property`'.
Upon further thinkies I believe there definitely is.
Asserts can only say that there shouldn't be more than 10 items in a list, or a path should _already_ exist.
It cannot say to create a path that does _not_ exist.
Nor to make something writeable if it currently is not.

Need to think through the syntax a little more.
Right now it's sorta both a function call, and a key:value pair.
Most of the values are worthless if it's just a true/false.

Are these also tests?
Should `can('read')` do a `$ chmod +r` if it doesn't already have it?
Or should it fail if not readable.

Upon rubber duckying with Ginny, I realized that they're not really properties...
They're '`tests`', or '`directives`'.
The same key may have different meanings, depending on it's test/directive context.

.Example context
[cols='1,3,3']
|===
| Keyword | Test context | Directive context

| readable
| File/directory can be read by the current user
| Make the file readable by the current user (`chmod +r`)

| exists
| File/directory exists
| Create (`touch`, `mkdir -p`) if not exists
|===

Tests should fail on a non-0 status.
Perhaps a config option for "exit on test failure", else continue running and report errors at the end.

But how to have a concise syntax to determine which is which?
Ooh, maybe they can become tests if they end with a `?`, else they're a directive.


== Casting
There is currently no casting.
This is a problem if we want to type a directory as a string, to avoid escaping spaces with backslash.


== Subtypes
Would be nice to have subtypes for paths.
`path:file`, `path:directory`, etc.

The typecheck an say it's not a directory, because it doesn't end in a trailing slash.
But the runtime validation will check if the file itself actually is a directory.


== Failing in subshells
If something exits with a non-zero status from a subshell, gotta make sure the rest of the execution does not continue.
Can set a `EXIT=0` before the subshell.
Within the sourced `.sh` file, the final line is `SUCCESS=true ; declare -p SUCCESS`.
The parent shell does a `test $SUCCESS == 'true' || exit 1`.


== Basic grammar
----
program        -> statement EOF

statement      -> parser_directive
                | declaration

declaration    -> section_decl
                | variable_decl

section_decl   -> identifier '{' declaration* '}'

variable_decl  -> identifier (type)? (expression)? ';'

expression     -> array
                | string
                | integer
                | boolean
                | path

array          -> '[' expression* ']'
----


== Basic syntax
[source]
----
untyped {
   key1  "value1";
   key2  "value2";
}


typed {
   key1  str  "value1";
   key2  array:str  [
      "one"
      "two"
      "three"
   ];
}


context {
   directories  array:path  [
      ~/Documents
      ~/Desktop
   ] {
      readable    # directive:  must be readable, `chmod +r`
      writable?   # test:       is writable? fail if not.
   }
}
----


== Rethink nested ``source``ing structure
Sourcing from a process substitution is really neat, and has clear benefits.
Can re-use common names across multiple files (`advance`, `peek`, etc.).

I'm running into clear drawbacks:

. Difficulty troubleshooting (sources all output to `stdout`)
. Difficulty testing

If each file does not contain *executable* code (kinda), it would be more testable.
Only variable & function declarations.
Each function can then be called from a `main.sh` file or something.

.parser.sh
[source,bash]
----
declare -gA TOKENS=()
declare -g  TOKEN=

function parse     { :; }
function p_advance { :; }
function p_peek    { :; }
function p_number  { ;: }
----

.main.sh
[source,bash]
----
function make_ast {
   scan
   parse
}

source 'parser.sh'
source 'lexer.sh'
----

There are some global variables that are not kept run-to-run.
Those should be explicitly reset each time.
For example, file/cursor information in the lexer.

I do feel that we lose a little bit of '`cleverness`' from our current approach.
However in the end, it's certainly more important to be testable and well written.

This, unlikely many of the other `hre-utils`, I want to be *good*, rather than just *neat*.


== Variables
=== Bash variables
How should bash variables work?

.Options
. Only allow for basic variables: `$VAR`
  .. Additionally allow `${VAR}` style
. Include support for basic array indexing: `${VAR[0]}`
. Include support for complex array operations (slices?): `${VAR[0:-2]}`

There's a slight deviation from traditional bash syntax in these arrays.
At that point, I may as well just use a better syntax, raerpb Bash's kinda convoluted approach.
I do need a syntax to separate environment variables from internal variables.
I can make these function calls tbh.

.idea #1, function calls
[source,conf]
----
global {
   path  env("PATH");
   name  self("user", "name");
}

user {
   name "Marcus";
   age  30;
}
----

The functions are variatic, and effective take a series of indices.
They would work in the same way the `api.conf()` function does.
Cannot do static typechecking, would need to be runtime in the compiler.
Though can use the type information in nifty ways.

_AS IT TURNS OUT... I FORGOT SOMETHING IMPORTANT._

I don't need to worry about indexes at all.
Bash does not support exporting an array into the environment.
It's a known bash bug that I've run into once or twice in the past.
Makes it way easier to pull in vars from the environment when they can only be simple key:value pairs.
Though still need a way to pull '`internal`' vars.
Saves repetition.

.idea #2, simple vars
[source,conf]
----
global {
   path  $PATH;
}
----


=== Internal variables
First idea is to just use a different prefix to designate internal variables.
This has the approach of being distinct from environment variables.
Though could lead one to mistakenly use `$` over `%`.

.idea #1, different prefix
[source,conf]
----
global {
   people [
      %user1.name
      %user2.name
   ];
}

user1 {
   name "Marcus";
}

user2 {
   name "Ginny";
}
----


=== String interpolation
Should string interpolation be able to handle arbitrary expressions?
Currently I think not.
There really aren't any expressions in the language.
It would really just be '`internal`' or environment variables.

[source,conf]
----
global {
   full  "%{user1.name} Aurelius";
   repo  "${HOME}/hg";
}

user1 {
   name  "Marcus";
}
----

I think the above examples definitely demonstrate the difficulty in distinguishing between `$`/`%`.
Other symbols I can use?


== What do I work on now?
For when I get stuck, what are things I can work on...

.Core features that *do not* yet work
* BATS tests
* Error handling
* Referencing bash environment variables
* Referencing interal variables?

.Core features that *do* work
* Merging child file -> parent
* Lexing, parsing, and compiling basic (non-directive) .config files
* Support for basic type checking
* Accessing variables from .config file
* Importing/including/extending to other .config files
* Directive/test contexts
* Error reporting
